# Sign Language Detection  

This project focuses on **real-time Sign Language Detection**, utilizing **MediaPipe** for hand tracking and a deep learning model for gesture classification. It covers **data collection, model training, and real-time inference**.

---

## Features  
✔ **Real-time hand tracking** with MediaPipe  
✔ **Sign gesture classification** using deep learning  
✔ **Dataset collection & preprocessing**  
✔ **Visualization tools** for evaluation  

---

## Usage  

### 1️⃣ Collect Data (Optional)  
Use **`data-collection.ipynb`** to capture and store hand gesture data.  

### 2️⃣ Train the Model  
Run **`sign-language-detection.ipynb`** for model training, which includes:  
- **LSTM & CNN architectures** for feature extraction  
- **TensorFlow/Keras** for implementation  

### 3️⃣ Run the Detection System  
Execute the **detection notebook** to test real-time sign recognition.  

---

## Project Structure  

📁 **`code/`** – Jupyter notebooks for **data collection & detection**  
📁 **`figures/`** – Visuals & model architecture diagrams  
📁 **`gifs/`** – Demonstration GIFs of the detection system  
