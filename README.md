# Sign Language Detection  

This project focuses on **real-time Sign Language Detection**, utilizing **MediaPipe** for hand tracking and a deep learning model for gesture classification. It covers **data collection, model training, and real-time inference**.

---

## Features  
âœ” **Real-time hand tracking** with MediaPipe  
âœ” **Sign gesture classification** using deep learning  
âœ” **Dataset collection & preprocessing**  
âœ” **Visualization tools** for evaluation  

---

## Usage  

### 1ï¸âƒ£ Collect Data (Optional)  
Use **`data-collection.ipynb`** to capture and store hand gesture data.  

### 2ï¸âƒ£ Train the Model  
Run **`sign-language-detection.ipynb`** for model training, which includes:  
- **LSTM & CNN architectures** for feature extraction  
- **TensorFlow/Keras** for implementation  

### 3ï¸âƒ£ Run the Detection System  
Execute the **detection notebook** to test real-time sign recognition.  

---

## Project Structure  

ğŸ“ **`code/`** â€“ Jupyter notebooks for **data collection & detection**  
ğŸ“ **`figures/`** â€“ Visuals & model architecture diagrams  
ğŸ“ **`gifs/`** â€“ Demonstration GIFs of the detection system  
